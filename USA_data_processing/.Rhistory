wass_Q_pgm(xx[i],tt[j])
})
})
),
npm = mean(sapply(1:Ngrid, function(i){
sapply(1:Ngrid, function(j){
wass_Q_npm(xx[i],tt[j])
})
})
),
oracle = mean(sapply(1:Ngrid, function(i){
sapply(1:Ngrid, function(j){
wass_oracle(xx[i],tt[j])
})
})
)
))
},mc.cores = NCORES)
rm(list = ls())
##################
library(fdadensity)
library(fdapace)
library(quadprog)
library(RColorBrewer)
library(ggplot2)
library(parallel)
#library(pracma)
#########################
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/CreateDensity.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/qf2pdf.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/qf2hist.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/nonpara_locreg_Q.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/vcm_locreg_Q.R")
## Define needed functions
## Calculates L2_distance between two matrix objects--------------
dist <- function(X,Y,p=2){
if(!is.matrix(X)){
X = matrix(X,1)
}
if(!is.matrix(Y)){
Y = matrix(Y,1)
}
D <- apply(Y,1, function(y){
apply(X,1, function(x){
sum(abs(x-y)^p)^(1/p)
})
})
return(D)
}
phi_xt = function(x,t){
if(t>=0 & t<=.5){
4 /((1 + exp(-40*(t-.25))) * (1 + exp(-40*(x-.25))))
}
else if (t >.5 & t<=1){
4/((1 + exp(40*(t-.75))) * (1 + exp(40*(x-.75))))
}
}
true_reg = function(x,t){
reg_norm = qnorm(seq(0.01,.99,length.out = 100), mean = phi_xt(x,t), sd = .1)
kk = sample(c(2,-2), 1, replace = TRUE)
reg = Transport_map(kk, reg_norm)
sort(reg, decreasing = FALSE)
}
Transport_map = function(k,x){
x - (sin(k*x)/abs(k))
}
wass_Q_pgm = function(x,t){
dist(true_reg(x,t), estd_Q_pgm(x,t))
}
wass_Q_npm = function(x,t){
dist(true_reg(x,t), estd_Q_npm(x,t))
}
wass_oracle = function(x,t){
dist(true_reg(x,t), fitted_oracle_quantile(x,t))
}
file_out="default.csv"
ni = 20;  n = 30
### draw random sample
gen_pred = replicate(ni, rbeta(n,1/2,1/2), simplify = F)
gen_T = replicate(ni, runif(1,0,1), simplify = F)
gen_QQ = lapply(1:ni, function(j){
lapply(1:n, function(i){
true_reg(gen_pred[[j]][i], gen_T[[j]])
#gen_quantile(gen_pred[[j]][i], gen_T[[j]])#gen_time_point[[j]][[i]])
})
})
gen_QQ = function(x,t){
nu =  rnorm(1, mean = phi_xt(x,t), sd = .1)
b =  1+phi_xt(x,t)
sig = rgamma(n = 1, shape = .5*b^2, scale = 1/(.5*b))
gen_Y_first = rnorm(n = 1, mean = nu, sd = sig)
kk = sample(c(2,-2), 1, replace = TRUE)
gen_Y_final = Transport_map(kk, pnorm((gen_Y_first-nu)/sig))
sort(gen_Y_final, decreasing = FALSE)
}
gen_QQ = lapply(1:ni, function(j){
lapply(1:n, function(i){
true_reg(gen_pred[[j]][i], gen_T[[j]])
#gen_quantile(gen_pred[[j]][i], gen_T[[j]])#gen_time_point[[j]][[i]])
})
})
gen_QQ
#   nu =  rnorm(1, mean = phi_xt(x,t), sd = .1)
#   b =  1+phi_xt(x,t)
#   sig = rgamma(n = 1, shape = .5*b^2, scale = 1/(.5*b))
#   gen_Y_first = rnorm(n = 1, mean = nu, sd = sig)
#   kk = sample(c(2,-2), 1, replace = TRUE)
#   gen_Y_final = Transport_map(kk, pnorm((gen_Y_first-nu)/sig))
#   sort(gen_Y_final, decreasing = FALSE)
# }
#
##Prep to feed into the regression model
Qin = matrix(unlist(gen_QQ), nrow = n*ni, ncol = 1000, byrow = TRUE)
Tin = unlist(gen_T)
Xin = unlist(gen_pred)
estd_Q_pgm = function(x,t){
obj = LocReg(Tin, Xin, Qin, x, t, bw= .4, ker='gaus', lower= -15, upper= 15)
return(obj)
}
estd_Q_npm = function(x,t){
obj = LocReg2(Tin, Xin, Qin, x, t, bw1= .4, bw2 = .3, ker='gaus', lower= -15, upper= 15)
return(obj)
}
wass_Q_pgm = function(x,t){
dist(true_reg(x,t), estd_Q_pgm(x,t))
}
wass_Q_npm = function(x,t){
dist(true_reg(x,t), estd_Q_npm(x,t))
}
gen_mu = unlist(lapply(1:ni, function(j){
lapply(1:n, function(i){
phi_xt(gen_pred[[j]][[i]], gen_T[[j]])
})
}))
fitted_mu = lm(gen_mu ~ Xin + rep(Tin, each = n))
fitted_mu_coeff = fitted_mu$coefficients
fitted_oracle_quantile = function(x,t){
reg_norm = qnorm(seq(0.01,.99,length.out = 100), mean = fitted_mu_coeff%*%c(1,x,t), sd = .1)
kk = sample(c(2,-2), 1, replace = TRUE)
reg = Transport_map(kk, reg_norm)
sort(reg, decreasing = FALSE)
}
wass_oracle = function(x,t){
dist(true_reg(x,t), fitted_oracle_quantile(x,t))
}
xx = Xin #seq(-1,1,length.out = Ngrid)
tt =  rep(Tin, each = n) #seq(0,1,length.out = Ngrid)
npm = mean(sapply(1:10, function(i){
sapply(1:10, function(j){
wass_Q_npm(xx[i],tt[j])
})
})
)
npm
rm(list = ls())
##################
library(fdadensity)
library(fdapace)
library(quadprog)
library(RColorBrewer)
library(ggplot2)
library(parallel)
#library(pracma)
#########################
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/CreateDensity.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/qf2pdf.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/qf2hist.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/nonpara_locreg_Q.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/vcm_locreg_Q.R")
true_reg = function(x,t){
zeta_xt = .1 + .2*x + .5*t^2
nu_xt = .6 + .2*sin(10*pi*t)
reg_norm = zeta_xt + nu_xt*qnorm(seq(0.01,.99, length.out = 1000))
reg_norm = sort(reg_norm, decreasing = FALSE)
kk = sample(c(2,-2), 1, replace = TRUE)
reg = Transport_map(kk, reg_norm)
sort(reg, decreasing = FALSE)
return(reg)
}
wass_Q_pgm = function(x,t){
dist(true_reg(x,t), estd_Q_pgm(x,t))
}
wass_Q_npm = function(x,t){
dist(true_reg(x,t), estd_Q_npm(x,t))
}
wass_oracle = function(x,t){
dist(true_reg(x,t), fitted_oracle_quantile(x,t))
}
file_out="default.csv"
ni = 20;  n = 30
NCORES = 35
Nsim = 5
Ngrid = 10
### draw random sample
gen_pred = replicate(ni, rbeta(n,1/2,1/2), simplify = F)
gen_T = replicate(ni, runif(1,0,1), simplify = F)
gen_QQ = lapply(1:ni, function(j){
lapply(1:n, function(i){
true_reg(gen_pred[[j]][i], gen_T[[j]])
#gen_quantile(gen_pred[[j]][i], gen_T[[j]])#gen_time_point[[j]][[i]])
})
})
Transport_map = function(k,x){
x - (sin(k*x)/abs(k))
}
gen_QQ = lapply(1:ni, function(j){
lapply(1:n, function(i){
true_reg(gen_pred[[j]][i], gen_T[[j]])
#gen_quantile(gen_pred[[j]][i], gen_T[[j]])#gen_time_point[[j]][[i]])
})
})
##Prep to feed into the regression model
Qin = matrix(unlist(gen_QQ), nrow = n*ni, ncol = 1000, byrow = TRUE)
Tin = unlist(gen_T)
Xin = unlist(gen_pred)
estd_Q_pgm = function(x,t){
obj = LocReg(Tin, Xin, Qin, x, t, bw= .4, ker='gaus', lower= -15, upper= 15)
return(obj)
}
estd_Q_npm = function(x,t){
obj = LocReg2(Tin, Xin, Qin, x, t, bw1= .4, bw2 = .3, ker='gaus', lower= -15, upper= 15)
return(obj)
}
wass_Q_pgm = function(x,t){
dist(true_reg(x,t), estd_Q_pgm(x,t))
}
wass_Q_npm = function(x,t){
dist(true_reg(x,t), estd_Q_npm(x,t))
}
xx = 1:10
tt = 1:10
pgm = mean(sapply(1: length(xx), function(i){
sapply(1:length(tt), function(j){
wass_Q_pgm(xx[i],tt[j])
})
})
)
wass_Q_pgm = function(x,t){
dist(true_reg(x,t), estd_Q_pgm(x,t))
}
rm(list = ls())
##################
library(fdadensity)
library(fdapace)
library(quadprog)
library(RColorBrewer)
library(ggplot2)
library(parallel)
#library(pracma)
#########################
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/CreateDensity.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/qf2pdf.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/qf2hist.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/nonpara_locreg_Q.R")
source("~/OneDrive - University of California, Davis/docs/Research/mortality_project_rcode/functions/vcm_locreg_Q.R")
## Define needed functions
## Calculates L2_distance between two matrix objects--------------
dist <- function(X,Y,p=2){
if(!is.matrix(X)){
X = matrix(X,1)
}
if(!is.matrix(Y)){
Y = matrix(Y,1)
}
D <- apply(Y,1, function(y){
apply(X,1, function(x){
sum(abs(x-y)^p)^(1/p)
})
})
return(D)
}
### calculates true quantile model at given x and t values
true_reg = function(x,t){
zeta_xt = .1 + .2*x + .5*t^2
nu_xt = .6 + .2*sin(10*pi*t)
reg = zeta_xt + nu_xt*qnorm(seq(0.01,.99,length.out = 1000))
reg = sort(reg,decreasing = FALSE)
return(reg)
}
true_reg = function(x,t){
zeta_xt = .1 + .2*x + .5*t^2
nu_xt = .6 + .2*sin(10*pi*t)
reg_norm = zeta_xt + nu_xt*qnorm(seq(0.01,.99, length.out = 1000))
reg_norm = sort(reg_norm, decreasing = FALSE)
kk = sample(c(2,-2), 1, replace = TRUE)
reg = Transport_map(kk, reg_norm)
sort(reg, decreasing = FALSE)
return(reg)
}
wass_Q_pgm = function(x,t){
dist(true_reg(x,t), estd_Q_pgm(x,t))
}
wass_Q_npm = function(x,t){
dist(true_reg(x,t), estd_Q_npm(x,t))
}
wass_oracle = function(x,t){
dist(true_reg(x,t), fitted_oracle_quantile(x,t))
}
ni = 20;  n = 30
NCORES = 35
Nsim = 5
Ngrid = 10
### draw random sample
gen_pred = replicate(ni, rbeta(n,1/2,1/2), simplify = F)
gen_T = replicate(ni, runif(1,0,1), simplify = F)
gen_QQ = lapply(1:ni, function(j){
lapply(1:n, function(i){
true_reg(gen_pred[[j]][i], gen_T[[j]])
#gen_quantile(gen_pred[[j]][i], gen_T[[j]])#gen_time_point[[j]][[i]])
})
})
Transport_map = function(k,x){
x - (sin(k*x)/abs(k))
}
gen_QQ = lapply(1:ni, function(j){
lapply(1:n, function(i){
true_reg(gen_pred[[j]][i], gen_T[[j]])
#gen_quantile(gen_pred[[j]][i], gen_T[[j]])#gen_time_point[[j]][[i]])
})
})
str(gen_QQ)
##Prep to feed into the regression model
Qin = matrix(unlist(gen_QQ), nrow = n*ni, ncol = 1000, byrow = TRUE)
Tin = unlist(gen_T)
Xin = unlist(gen_pred)
estd_Q_pgm = function(x,t){
obj = LocReg(Tin, Xin, Qin, x, t, bw= .4, ker='gaus', lower= -15, upper= 15)
return(obj)
}
estd_Q_npm = function(x,t){
obj = LocReg2(Tin, Xin, Qin, x, t, bw1= .4, bw2 = .3, ker='gaus', lower= -15, upper= 15)
return(obj)
}
wass_Q_pgm = function(x,t){
dist(true_reg(x,t), estd_Q_pgm(x,t))
}
wass_Q_npm = function(x,t){
dist(true_reg(x,t), estd_Q_npm(x,t))
}
xx = 1:10
tt = 1:10
pgm = mean(sapply(1: length(xx), function(i){
sapply(1:length(tt), function(j){
wass_Q_pgm(xx[i],tt[j])
})
})
)
xx = Xin #seq(-1,1,length.out = Ngrid)
tt =  rep(Tin, each = n) #seq(0,1,length.out = Ngrid)
pgm = mean(sapply(1: 10, function(i){
sapply(1:10, function(j){
wass_Q_pgm(xx[i],tt[j])
})
})
)
pgm
npm = mean(sapply(1:length(xx), function(i){
sapply(1:length(tt), function(j){
wass_Q_npm(xx[i],tt[j])
})
})
)
npm = mean(sapply(1:10, function(i){
sapply(1:10, function(j){
wass_Q_npm(xx[i],tt[j])
})
})
)
npm
gen_mu = unlist(lapply(1:ni, function(j){
lapply(1:n, function(i){
.1+ .2*gen_pred[[j]][[i]] + .5*(gen_T[[j]])^2
})
}))
gen_sig = unlist(lapply(1:ni, function(j){
lapply(1:n, function(i){
.6 +  .2*sin(10*pi*gen_T[[j]]^2)
})
}))
fitted_mu = lm(gen_mu ~ Xin + rep(Tin, each = n))
fitted_mu_coeff = fitted_mu$coefficients
fitted_sig = lm(gen_sig ~ Xin + rep(Tin, each = n))
fitted_sig_coeff = fitted_sig$coefficients
fitted_oracle_quantile = function(x,t){
as.numeric(fitted_mu_coeff%*%c(1,x,t)) +
as.numeric((fitted_sig_coeff%*%c(1,x,t)))*qnorm(seq(0.01,.99,length.out = 1000))
}
wass_oracle = function(x,t){
dist(true_reg(x,t), fitted_oracle_quantile(x,t))
}
oracle = mean(sapply(1:10, function(i){
sapply(1:10, function(j){
wass_oracle(xx[i],tt[j])
})
})
)
oracle
library(Frechet)
library(frechet)
rm(list = ls())
devtools::load_all("~/OneDrive - University of California, Davis/docs/Research/tPACE")
devtools::document("~/OneDrive - University of California, Davis/docs/Research/tPACE")
# Set the number of subjects (N) and the
# number of measurements per subjects (M)
N <- 30
M <- 100
set.seed(123)
# Define the continuum
s <- seq(0,10,length.out = M)
# Define the mean and 2 eigencomponents
meanFunct <- function(s) s + 10*exp(-(s-5)^2)
eigFunct1 <- function(s) +cos(2*s*pi/10) / sqrt(5)
eigFunct2 <- function(s) -sin(2*s*pi/10) / sqrt(5)
# Create FPC scores
Ksi <- matrix(rnorm(N*2), ncol=2);
Ksi <- apply(Ksi, 2, scale)
Ksi <- Ksi %*% diag(c(5,2))
# Create Y_true
yTrue <- Ksi %*% t(matrix(c(eigFunct1(s),eigFunct2(s)), ncol=2)) + t(matrix(rep(meanFunct(s),N), nrow=M))
L3 <- MakeFPCAInputs(IDs = rep(1:N, each=M), tVec=rep(s,N), t(yTrue))
# Estimation
res<-FPCA(Ly,Lt) # LW is default method for sparse data
# Estimation
res<-FPCA(L3$Ly,L3$Lt) # LW is default method for sparse data
res$sigma2
(res$optns)$useLWSigma2 # TRUE: LW method; FALSE: PACE
GetLWSigma2(Ly,Lt) # LW estimator
GetLWSigma2(L3$Ly,L3$Lt) # LW estimator
optns<-list(useLWSigma2=FALSE) # use pace method
res1<-FPCA(Ly,Lt,optns=optns)
res1<-FPCA(L3$Ly,L3$Lt,optns=optns)
res1$sigma2
(res1$optns)$useLWSigma2
optns<-list(useLWSigma2=TRUE) # use pace method
res1<-FPCA(L3$Ly,L3$Lt,optns=optns)
res1$sigma2
(res1$optns)$useLWSigma2
res$sigma2
(res$optns)$useLWSigma2 # TRUE: LW method; FALSE: PACE
GetLWSigma2(L3$Ly,L3$Lt) # LW estimator
optns<-list(useLWSigma2=TRUE) # use pace method
res1<-FPCA(L3$Ly,L3$Lt,optns=optns)
res1$sigma2
(res1$optns)$useLWSigma2
GetLWSigma2(L3$Ly,L3$Lt)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(magrittr)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(lubridate)
library(plyr)
library(gridExtra)
df1 = read.csv("~/Dropbox/covid/data/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv",header=FALSE)
dates=unlist(df1[1,setdiff(1:(dim(df1)[2]),1:11)], use.names=FALSE)
df2 = read.csv("~/Dropbox/covid/data/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv",header=FALSE, skip = 1)
df_dates = df2[-c(1:6,8:11)]
colnames(df_dates)[1] = "state"
colnames(df_dates)[2: dim(df_dates)[2]] = as.character(dates)
unique(df_dates$state)
data_spl = lapply(unique(df_dates$state), function(prov){
subset(df_dates, df_dates$state == prov)
})
cases = t(sapply(1: length(data_spl), function(prov){
as.numeric(colSums(data_spl[[prov]][,-1]))
}))
cases_df = as.data.frame(cbind(as.character(unique(df_dates$state)),cases))
colnames(cases_df) = c("state",as.character(dates))
#put it into long format
cases_df1 = cases_df %>% melt(id.vars = "state")
cases_df1 = cases_df1[order(cases_df1$state),]
names(cases_df1) = c("state", "date", "total_cases")
cases_df1$date = cases_df1$date %>% as.Date("%m/%d/%y")
cases_df1$total_cases = cases_df1$total_cases%>% as.numeric()
cases_df1 = cases_df1 %>% mutate(new_cases = total_cases - dplyr::lag(total_cases)) #Create new deaths
head(cases_df1)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(magrittr)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(lubridate)
library(plyr)
library(gridExtra)
df1 = read.csv("~/Dropbox/covid/data/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv" ,header=FALSE)
dates=unlist(df1[1,setdiff(1:(dim(df1)[2]),1:11)], use.names=FALSE)
df2 = read.csv("~/Dropbox/covid/data/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv",header=FALSE, skip = 1)
df_dates = df2[-c(1:6,8:11)]
colnames(df_dates)[1] = "state"
colnames(df_dates)[2: dim(df_dates)[2]] = as.character(dates)
unique(df_dates$state)
data_spl = lapply(unique(df_dates$state), function(prov){
subset(df_dates, df_dates$state == prov)
})
cases = t(sapply(1: length(data_spl), function(prov){
as.numeric(colSums(data_spl[[prov]][,-1]))
}))
cases_df = as.data.frame(cbind(as.character(unique(df_dates$state)),cases))
colnames(cases_df) = c("state",as.character(dates))
#put it into long format
cases_df1 = cases_df %>% melt(id.vars = "state")
cases_df1 = cases_df1[order(cases_df1$state),]
names(cases_df1) = c("state", "date", "total_cases")
cases_df1$date = cases_df1$date %>% as.Date("%m/%d/%y")
cases_df1$total_cases = cases_df1$total_cases%>% as.numeric()
cases_df1 = cases_df1 %>% mutate(new_cases = total_cases - dplyr::lag(total_cases)) #Create new deaths
str(cases_df1)
cases_df1$total_cases[cases_df1$date = "2021-01-01"]
cases_df1$total_cases[cases_df1$date = "2021-01-01",]
cases_df1$total_cases[cases_df1$date == "2021-01-01"]
